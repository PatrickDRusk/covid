{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating implied infection numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tries to compute what the full infection numbers in the past and present likely were/are.\n",
    "\n",
    "It does so in the past by blending variables for \"median days from infection to death\" and \"infection fatility rate\" (IFR) with smoothed death rates. In other words, days_to_death days before date D, there must have been roughly (deaths_on_date_D / IFR) infections to end up with a given number of deaths on date D.\n",
    "\n",
    "It does in the present to looking at what percentage of infections were confirmed on the last day calculated in the past, and applying that percentage to the new infections found since then. That doesn't quite take into account if there is a significant ramping of testing during that time, but it should be close enough.\n",
    "\n",
    "The principal source of death data is files from the NY Times, supplemented by a more accurate DateOfDeath.csv from Massachusetts. The source of testing data is The COVID Tracking Project, maintained by The Atlantic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Prior to running this notebook, you should retrieve the latest DateOfDeath.csv file by:\n",
    "\n",
    "1. going to https://www.mass.gov/info-details/covid-19-response-reporting,\n",
    "2. downloading the raw data zip from the line saying \"Raw data used to create the dashboard is available here:\"\n",
    "3. copying the DateofDeath.csv in that file to the same directory as the notebook\n",
    "\n",
    "Yeah, that could be automated. Just haven't done it yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earliest date that there is sufficient data for all states, including MA\n",
    "EARLIEST_DATE = pandas.Period('2020-03-10', freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the state metadata\n",
    "meta = pandas.read_csv('nyt_states_meta.csv')\n",
    "meta.sort_values('Pop', ascending=False).head()\n",
    "meta['Country'] = 'USA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in state data from NY Times and reduce it to interesting columns, joined with the data above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nyt_csv(uri):\n",
    "    stats = pandas.read_csv(uri)\n",
    "    stats = stats[stats.state.isin(meta.State)][['date', 'state', 'deaths']]\n",
    "    stats.columns = ['Date', 'State', 'Deaths']\n",
    "    stats.Date = [pandas.Period(str(v)) for v in stats.Date]\n",
    "    stats = stats[stats.Date >= EARLIEST_DATE]\n",
    "\n",
    "    stats = stats.set_index(['State', 'Date']).sort_index()\n",
    "    # Pull in the statistics for states\n",
    "    stats = stats.join(meta.set_index('State'))\n",
    "\n",
    "    # Remove territories\n",
    "    stats = stats[~stats.ST.isin(['AS', 'GU', 'MP', 'PR', 'VI'])]\n",
    "\n",
    "    return stats.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_stats = read_nyt_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv')\n",
    "nyt_stats_live = read_nyt_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/live/us-states.csv')\n",
    "nyt_stats[nyt_stats.State == 'New York'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the live stats if the daily file has not yet rolled\n",
    "if nyt_stats.Date.max() < nyt_stats_live.Date.max():\n",
    "    print(\"Pulling in live stats\")\n",
    "    nyt_stats = pandas.concat([nyt_stats, nyt_stats_live], sort=True)\n",
    "    nyt_stats.index = list(range(len(nyt_stats)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve the Massachusetts data by using the DateOfDeath.csv from MA site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the latest MA data is very incomplete, replace the most recent three days with\n",
    "# the average from the prior five days\n",
    "days = 3\n",
    "cur_date = pandas.Period(nyt_stats.Date.max(), freq='D')\n",
    "cutoff_date = cur_date - days\n",
    "ma = pandas.read_csv('DateOfDeath.csv').iloc[:, [0, 2, 4]]\n",
    "ma.columns = ['Date', 'Confirmed', 'Probable']\n",
    "ma['Deaths'] = ma.Confirmed + ma.Probable\n",
    "ma.Date = [pandas.Period(str(v)) for v in ma.Date]\n",
    "ma = ma[(ma.Date >= EARLIEST_DATE) & (ma.Date <= cutoff_date)]\n",
    "ma = ma.set_index('Date').sort_index()[['Deaths']]\n",
    "extra_dates = pandas.period_range(end=cur_date, periods=days, freq='D')\n",
    "avg_deaths = (ma.loc[cutoff_date].Deaths - ma.loc[cutoff_date-5].Deaths) / 5\n",
    "new_deaths = [ma.Deaths[-1] + (avg_deaths * (i+1)) for i in range(days)]\n",
    "ma = pandas.concat([ma, pandas.DataFrame(new_deaths, index=extra_dates, columns=['Deaths'])])\n",
    "ma.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = nyt_stats[nyt_stats.State == 'Massachusetts'].index.copy()\n",
    "spork = ma.copy()\n",
    "spork.index = indices\n",
    "nyt_stats.loc[indices, 'Deaths'] = spork.Deaths\n",
    "nyt_stats[nyt_stats.State == 'Massachusetts'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in the testing information from the COVID Tracking Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_stats = pandas.read_csv('https://covidtracking.com/api/v1/states/daily.csv')\n",
    "\n",
    "# Remove territories\n",
    "ct_stats = ct_stats[~ct_stats.state.isin(['AS', 'GU', 'MP', 'PR', 'VI'])]\n",
    "\n",
    "# Choose and rename a subset of columns\n",
    "ct_stats = ct_stats[['date', 'state', 'positive', 'negative']]\n",
    "ct_stats.columns = ['Date', 'ST', 'Pos', 'Neg']\n",
    "\n",
    "# Set the index to state and date\n",
    "ct_stats.Date = [pandas.Period(str(v)) for v in ct_stats.Date]\n",
    "ct_stats = ct_stats[ct_stats.Date >= EARLIEST_DATE]\n",
    "ct_stats = ct_stats.set_index(['ST', 'Date'])\n",
    "\n",
    "# Pull in the statistics for states\n",
    "ct_stats = ct_stats.join(meta.set_index('ST')).reset_index().sort_values(['ST', 'Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct for various jumps in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Various states have had days on which they dramatically scaled up their number of deaths for various reasons (usually starting to include probable deaths). The function above and code correct somewhat for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, on June 25, NJ started reporting \"probable\" deaths (much later than other states) and lumped 1854 past ones on that day, throwing off a lot of trend analysis. This code distributes those over the past in proportion to the confirmed deaths. Technically, the probables should be weighted earlier, but this should mostly suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread_deaths(stats, state, num_deaths, deaths_date, realloc_end_date=None):\n",
    "    realloc_end_date = realloc_end_date or deaths_date\n",
    "    st = stats[(stats.State == state) & (stats.Date <= deaths_date)]\n",
    "    indices = st.index.copy()\n",
    "    st = st.set_index('Date')[['Deaths']].copy()\n",
    "    orig_total = st.loc[deaths_date, 'Deaths']\n",
    "    st.loc[deaths_date, 'Deaths'] -= num_deaths\n",
    "    new_total = st.loc[deaths_date, 'Deaths']\n",
    "    st['Daily'] = st.Deaths - st.shift(1).Deaths\n",
    "    st['DailyAdj'] = (st.Daily * (orig_total / new_total)) - st.Daily\n",
    "    st['CumAdj'] = st.DailyAdj.sort_index().cumsum().sort_index()\n",
    "    st.loc[deaths_date, 'CumAdj'] = 0.\n",
    "    st = st.reset_index()\n",
    "    st.index = indices\n",
    "    stats.loc[indices, 'Deaths'] += st.CumAdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_ADJUSTMENTS = (\n",
    "    ('New Jersey', 1854, '2020-06-25'),\n",
    "    ('New York', 608, '2020-06-30'),  # technically, most of these apparently happened at least three weeks earlier\n",
    "    ('Illinois', 123, '2020-06-08'),\n",
    "    ('Michigan', 220, '2020-06-05'),\n",
    ")\n",
    "\n",
    "for state, deaths, deaths_date in STATE_ADJUSTMENTS:\n",
    "    spread_deaths(nyt_stats, state, deaths, deaths_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group on date and calculate new stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt = nyt_stats.groupby('Date').sum().sort_index()[['Deaths']].copy()\n",
    "ct = ct_stats.groupby('Date').sum().sort_index()[['Pos', 'Neg']].copy()\n",
    "\n",
    "# Calculate per-capita values\n",
    "ct['PctPos'] = ct.Pos / (ct.Pos + ct.Neg)\n",
    "\n",
    "# Calculate daily deaths and smoothed (avg of trailing 7 days) deaths\n",
    "nyt['Daily'] = (nyt.Deaths - nyt.shift().Deaths)\n",
    "nyt['Deaths7'] = (nyt.Deaths - nyt.shift(7).Deaths) / 7\n",
    "\n",
    "# Calculate confirmed tests based on smoothed weekly data\n",
    "ct7 = ct.shift(7)[['Pos', 'Neg']]\n",
    "ct['NRatio'] = (ct.Neg - ct7.Neg) / (ct.Pos - ct7.Pos)\n",
    "ct['DailyConfirms'] = (ct.Pos - ct7.Pos) / 7\n",
    "\n",
    "ct.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now for the charts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infections_df(scenarios):\n",
    "    data = {}\n",
    "    for name, death_lag, ifr_high, ifr_low in scenarios:\n",
    "        # Calculate the IFR to apply for each day\n",
    "        ifr = pandas.Series(numpy.linspace(ifr_high, ifr_low, len(nyt)), index=nyt.index)\n",
    "        # Calculate the infections in the past\n",
    "        infections = nyt.shift(-death_lag).Deaths7 / ifr\n",
    "        \n",
    "        # Find out the ratio of infections that were detected on the last date in the past\n",
    "        last_date = infections.index[-(death_lag+1)]\n",
    "        last_ratio = infections.loc[last_date] / ct.loc[last_date, 'DailyConfirms']\n",
    "        \n",
    "        # Apply that ratio to the dates since that date\n",
    "        infections.iloc[-death_lag:] = ct.DailyConfirms.iloc[-death_lag:] * last_ratio\n",
    "\n",
    "        print(1 / last_ratio)\n",
    "        data[name] = infections\n",
    "\n",
    "    return pandas.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS = (('20', 20, 0.01, 0.01), ('18', 18, 0.01, 0.01), ('16', 16, 0.01, 0.01), )\n",
    "\n",
    "df = get_infections_df(SCENARIOS)\n",
    "foo = df.plot(title=\"New Infections Estimates, varying average days to death, IFR = 1.0%\", figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS = (('1.3%', 18, 0.013, 0.013), ('1.0%', 18, 0.01, 0.01), ('0.7%', 18, 0.007, 0.007), )\n",
    "\n",
    "df = get_infections_df(SCENARIOS)\n",
    "foo = df.plot(title=\"New Infections Estimates, varying IFR, days to death = 18\", figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS = (('1.2% - 0.8%', 18, 0.012, 0.008), ('1.0% - 0.7%', 18, 0.01, 0.007), ('0.9% - 0.6%', 18, 0.009, 0.006), )\n",
    "\n",
    "df = get_infections_df(SCENARIOS)\n",
    "foo = df.plot(title=\"Infection Estimations, improving IFR, days to death = 18\", figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS = (('1.0% - 0.6%', 18, 0.01, 0.006), )\n",
    "\n",
    "df = get_infections_df(SCENARIOS)\n",
    "foo = df.plot(title=\"Infection Estimations, my hunch\", figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIOS = (('1.2% - 0.5%', 20, 0.012, 0.005), )\n",
    "\n",
    "df = get_infections_df(SCENARIOS)\n",
    "foo = df.plot(title=\"Worst case? 20 days to death, improving IFR\", figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
