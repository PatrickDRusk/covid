{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating state-by-state implied infection numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tries to compute what the full infection numbers in the past and present likely were/are.\n",
    "\n",
    "It does so in the past by blending variables for \"median days from infection to death\" and \"infection fatility rate\" (IFR) with smoothed death rates. In other words, days_to_death days before date D, there must have been roughly (deaths_on_date_D / IFR) infections to end up with a given number of deaths on date D.\n",
    "\n",
    "When looking at the most recent days_to_death days, it looks up what percentage of infections were confirmed on the last day calculated in the past, and applies that percentage to the new infections found since then. It normalizes a bit by the amount of testing done on each day to try to handle significant ramping up/down of testing during that time, but the recent projections are admittedly sketchy.\n",
    "\n",
    "The principal source of death data is files from the NY Times, supplemented by a more accurate DateOfDeath.xlsx from Massachusetts. The source of testing data is The COVID Tracking Project, maintained by The Atlantic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Prior to running this notebook, you should retrieve the latest DateOfDeath.xlsx file by:\n",
    "\n",
    "1. going to https://www.mass.gov/info-details/covid-19-response-reporting,\n",
    "2. downloading the raw data zip from the line saying \"Raw data used to create the dashboard is available here:\"\n",
    "3. copying the DateofDeath.xlsx in that file to the same directory as the notebook\n",
    "\n",
    "Yeah, that could potentially be automated, but MA made that really hard the way they implemented it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common import load_data, smooth_series, calc_mid_weekly_average\n",
    "from common import calc_state_stats, get_infections_df, find_smooth_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earliest date that there is sufficient data for all states, including MA\n",
    "EARLIEST_DATE = pandas.Period('2020-03-10', freq='D')\n",
    "\n",
    "# Set a latest date when the most recent days have garbage (like on or after holidays)\n",
    "LATEST_DATE = pandas.Period('2020-12-23', freq='D')\n",
    "LATEST_DATE = pandas.Period('2021-01-03', freq='D')\n",
    "LATEST_DATE = None\n",
    "\n",
    "# Set a number of recent days to not display in the graphs for lack of future days to smooth them\n",
    "NON_DISPLAY_DAYS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latest_date, meta, nyt_stats, ct_stats = load_data(EARLIEST_DATE, LATEST_DATE)\n",
    "latest_displayed = latest_date - NON_DISPLAY_DAYS\n",
    "print(f\"Latest date = {str(latest_date)}; latest displayed = {str(latest_displayed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the two datasets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = ct_stats.set_index(['ST', 'Date']).sort_index()[['Pos', 'Neg']]\n",
    "nyt1 = nyt_stats.set_index(['ST', 'Date']).sort_index()[['Deaths']]\n",
    "both = ct1.join(nyt1)\n",
    "meta_tmp = meta.set_index('ST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [calc_state_stats(state, df, meta_tmp, latest_date)\n",
    "          for state, df in both.reset_index().groupby('ST')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pandas.concat(states).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate new stats, state by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median number of days between being exposed and developing illness\n",
    "INCUBATION = 4\n",
    "\n",
    "# Number of days one is infectious (this isn't actually used yet)\n",
    "INFECTIOUS = 10\n",
    "\n",
    "# Median days in between exposure and death\n",
    "DEATH_LAG = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where you set variables for IFR assumptions\n",
    "\n",
    "# Note that this IFR represents a country-wide average on any given day, but the IFRs\n",
    "# are actually adjusted up/down based on median age and nursing home residents per capita\n",
    "\n",
    "# This set represents my worst case scenario (in my 95% CI interval)\n",
    "# Start by setting the inital and final IFRs\n",
    "IFR_S, IFR_E = 0.013, 0.006\n",
    "# Then set dates in between by which it linearly scales to various targets\n",
    "IFR_BREAKS = [['2020-04-30', 0.0095], ['2020-07-31', 0.007], ['2020-09-15', 0.006]]\n",
    "\n",
    "# This set is my optimistic scenario\n",
    "IFR_S, IFR_E = 0.01, 0.0025\n",
    "IFR_BREAKS = [['2020-04-30', 0.0075], ['2020-07-31', 0.0045], ['2020-09-15', 0.0025]]\n",
    "\n",
    "# This set is a highly optimistic scenario that matches the recent CDC data\n",
    "IFR_S, IFR_E = 0.009, 0.002\n",
    "IFR_BREAKS = [['2020-04-30', 0.007], ['2020-07-31', 0.003], ['2020-09-15', 0.002]]\n",
    "\n",
    "# This is my expected scenario\n",
    "IFR_S, IFR_E = 0.01, 0.004\n",
    "IFR_BREAKS = [['2020-04-30', 0.0085], ['2020-07-31', 0.005], ['2020-09-15', 0.004]]\n",
    "\n",
    "IFR_PARAMS = {\n",
    "    \"High IFR (1.3%->0.6%)\": (0.013, 0.006,\n",
    "                                 [['2020-04-30', 0.0095], ['2020-07-31', 0.007], ['2020-09-15', 0.006]]),\n",
    "    \"Expected IFR (1.0%->0.4%)\": (0.01, 0.004,\n",
    "                              [['2020-07-31', 0.005], ['2020-09-15', 0.004]]),\n",
    "    \"Low IFR (1.0%->0.25%)\": (0.01, 0.0025,\n",
    "                                 [['2020-04-30', 0.0075], ['2020-07-31', 0.0045], ['2020-09-15', 0.0025]]),\n",
    "    \"CDC Estimates (0.9%->0.2%)\": (0.009, 0.002,\n",
    "                         [['2020-04-30', 0.007], ['2020-07-31', 0.003], ['2020-09-15', 0.002]]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RESULTS = {}\n",
    "for title, (IFR_S, IFR_E, IFR_BREAKS) in IFR_PARAMS.items():\n",
    "    IFR_S_S, IFR_E_S = f'{100*IFR_S:.1f}%', f'{100*IFR_E:.2f}%'\n",
    "    infected_states = get_infections_df(states, meta, DEATH_LAG, IFR_S, IFR_E, IFR_BREAKS, INCUBATION, INFECTIOUS)\n",
    "    foo = infected_states.reset_index()[['Date', 'NewInf']]\n",
    "    foo = foo[foo.Date <= latest_displayed].groupby('Date').sum().NewInf\n",
    "    foo = foo.cumsum()\n",
    "    foo = pandas.Series([int(x) for x in foo], index=foo.index)\n",
    "    print(f\"Total infected by {latest_date}: {int(foo.iloc[-1]):,}\")\n",
    "    RESULTS[title] = foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam = infected_states.reset_index()[['Date', 'Confirms7']].groupby('Date').sum().cumsum()\n",
    "fam = fam.loc[:latest_displayed]\n",
    "fam = pandas.Series([int(x) for x in fam.Confirms7], index=fam.index)\n",
    "RESULTS[\"Confirmed\"] = fam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EST_LINE = str(latest_date - (DEATH_LAG - 1))\n",
    "print(f\"Vertical line marking recent estimations set at {EST_LINE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(RESULTS.keys())\n",
    "values = list(RESULTS.values())\n",
    "df = pandas.concat(values, axis=1)\n",
    "df.columns = columns\n",
    "df.tail() / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam = (df/1000000).plot(title=f\"Estimates of Total Infections in the US\",\n",
    "                        figsize=(13,5), ylim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
